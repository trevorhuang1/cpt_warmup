{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "toc: true\n",
    "comments: true\n",
    "layout: post\n",
    "title: 5.3 Computing Bias Lesson\n",
    "description: Computing Bias Lesson\n",
    "courses: {compsci: {week: 4}}\n",
    "type: hacks\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computing Bias - Hanlun\n",
    "What is it?\n",
    "- Computing bias is a bias that exists within algorithms that unfairly discriminate against certain individuals or groups, creating unfair outcomes\n",
    "- Computing innovations reflect biases because algorithms and data are influenced by the people who contributed to it, so computing biases can be embedded at every level of development \n",
    "- Algorithm bias should be reduced so computer innovations can combat existing user bias\n",
    "![img]({{site.baseurl}}//images/computingbias.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Popcorn Hack #1: \n",
    "Which of the following scenarios is an example of computing bias?\n",
    "\n",
    "A. An email filtering system accurately categorizes emails into spam and non-spam based on a diverse set of features, minimizing false positives and false negatives. <br>\n",
    "B. A navigation app provides real-time traffic updates and alternate routes to users, considering various factors such as traffic volume, road closures, and weather conditions. <br>\n",
    "C. An image recognition algorithm identifies objects in photographs with high accuracy, regardless of the gender, ethnicity, or age of the individuals depicted.<br>\n",
    "D. An automated hiring system consistently favors candidates from specific educational institutions and backgrounds, resulting in the exclusion of qualified applicants from diverse backgrounds."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Types of Computing Bias - Trevor\n",
    "Computing bias can be either intentional or unintentional and as said before, this bias is a result of human biases in development. Here are some examples:\n",
    "\n",
    "- Data bias: when the data set does not reflect the real world values\n",
    "    - Ex: A company is developing an algorithm to see whether or not a product has positive or negative online reviews. However, the training data might over-represent overly negative or positive opinions that are posted online which wouldn’t reflect the real-world popularity of the product\n",
    "    <img src=\"https://www.wallstreetmojo.com/wp-content/uploads/2023/05/Data-Bias-Meaning.png\">\n",
    "- Human bias: People who make the programs may bring in their own biases whether consciously or unconsciously\n",
    "    - Ex: A software development team is working on a code review algorithm. They all have experience using Language X and so they believe that developers using Language X are more qualified and so their algorithm reflects that. This uses their individual traits and applies it to the entire group of coders using Language X.\n",
    "- Algorithmic bias reflects the data bias and human bias and often amplifies it. However, bias can arise from the structure and decision making of the program itself\n",
    "    - Ex: A program is designed to automate the loan approval system. It uses information from income, employment history, and credit score. However, the algorithmn can produce biased results based on trends from certain job occupations which may disproportionally affect certain groups\n",
    "    <img src=\"https://andipeng.com/publication/what-you-see-is-what-you-get-the-impact-of-representation-criteria-on-human-bias-in-hiring/featured.png\" style=\"width:800px;height:500px\"><br>\n",
    "There are many more nuanced types of computing biases which you can find here: https://developers.google.com/machine-learning/crash-course/fairness/types-of-bias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Popcorn Hack #2:\n",
    "An online example of computing bias is when an HP computer’s facial recognition system couldn’t track the face of someone with darker skin. Why is this and what type of bias is it? Do you think it was intentional or unintentional?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explicit and Implicit Data - Lakshanya\n",
    "- Explicit data is information you give an app or site\n",
    "- Implicit data is the information it collects based on your activity\n",
    "- For example, with Netflix, the explicit data it collects includes your rating of movies (thumbs up, thumbs down) and your personal information. The implicit data it collects includes when you watch, what you binge, and the frequently selected genres.\n",
    "- This data collection is also known as user bias. More bias comes in when Netflix shows its exclusives before any of the regular items to gain subscriptions.\n",
    "\n",
    "<img src=\"https://media.licdn.com/dms/image/C5612AQEhXVSXgpPbjg/article-cover_image-shrink_720_1280/0/1619039092615?e=2147483647&v=beta&t=lCWX45_3Q0ACHa_YkzOuhpjKtY5fFmB57Ssy0prvHdE\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Popcorn Hack #3:\n",
    "\n",
    "- What is another scenario of data collection in everyday situations?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mitigation Strategies: - Matthew\n",
    "\n",
    "- Obtain more diverse data (ex: racist computer)\n",
    "- Pre-processing: Writing an algorithm that adjusts to datasets to check for bias before using it as an input. It's about cleaning up and organizing the raw data and makes it more suitable for building or training models. \n",
    "\n",
    "- In-processing: This occurs during the processing or analysis of data within a system or model. The algorithm will manipulate and transform the data as it goes through the model during its active use.(ex: if the algorithm was processing images it would rescale the image to keep consistent dimensions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mitigation Strategies: - Aditya\n",
    "Post-processing: This type of strategy is comprised of 3 parts, input correction, classifier correction, output correction\n",
    "input correction: very similar to pre-processing strategies, but instead of applying the modifications in the data before the training process, the modifications are applied to the testing data once the model has been trained\n",
    "Classifier correction: adjusts the algorithm to remove discrimination\n",
    "Output correction: directly modifies the output of any algorithm in order to remove discrimination"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hacks:\n",
    "Problem: Biased Predictive Policing Algorithm: A city implements a predictive policing algorithm to allocate law enforcement resources more efficiently. \n",
    "However, concerns arise as community members and activists notice that the algorithm appears to disproportionately target certain neighborhoods, leading to over-policing and potential violations of civil rights.\n",
    "Provide a solution to how this situation can be resolved, and how the computing bias can be removed. Explain which method of mitigation you will use and how it works. "
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
